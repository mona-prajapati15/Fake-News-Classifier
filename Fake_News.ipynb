{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeadd19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hii\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas sklearn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f6f725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\hii\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/41.5 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/41.5 kB ? eta -:--:--\n",
      "     -------------------------------------  41.0/41.5 kB 217.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- 41.5/41.5 kB 200.7 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hii\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "   ---------------------------------------- 0.0/273.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/273.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/273.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/273.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/273.6 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 41.0/273.6 kB 326.8 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 61.4/273.6 kB 544.7 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 81.9/273.6 kB 381.3 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 81.9/273.6 kB 381.3 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 112.6/273.6 kB 385.0 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 163.8/273.6 kB 466.9 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 194.6/273.6 kB 491.5 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 204.8/273.6 kB 518.8 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 245.8/273.6 kB 502.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 273.6/273.6 kB 526.7 kB/s eta 0:00:00\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.2.1 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\HII\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script nltk.exe is installed in 'c:\\Users\\HII\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb51313",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce824ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "true_df = pd.read_csv(\"True.csv\")\n",
    "fake_df = pd.read_csv(\"Fake.csv\")\n",
    "\n",
    "# Label the data\n",
    "true_df[\"label\"] = 1   # Real\n",
    "fake_df[\"label\"] = 0   # Fake\n",
    "\n",
    "# Merge them\n",
    "data = pd.concat([true_df, fake_df], ignore_index=True)\n",
    "data = data.sample(frac=1).reset_index(drop=True)  # Shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf1d09",
   "metadata": {},
   "source": [
    "Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c6acd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HII\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f3411e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))  # Load once only\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "data[\"clean_text\"] = data[\"text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ae28d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'text', 'subject', 'date', 'label', 'clean_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2675b3c5",
   "metadata": {},
   "source": [
    "Vectorize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3ddaa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.7)\n",
    "X = vectorizer.fit_transform(data[\"clean_text\"])\n",
    "y = data[\"label\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc776320",
   "metadata": {},
   "source": [
    "Train/Test Split + Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eef82a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9501113585746103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      4708\n",
      "           1       0.93      0.97      0.95      4272\n",
      "\n",
      "    accuracy                           0.95      8980\n",
      "   macro avg       0.95      0.95      0.95      8980\n",
      "weighted avg       0.95      0.95      0.95      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
